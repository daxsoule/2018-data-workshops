{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Data_Quality_Report_Amin_Ilia.ipynb",
   "version": "0.3.2",
   "views": {},
   "default_view": {},
   "provenance": [
    {
     "file_id": "1WZsYRYfap0BfsqrVhaLA4rin-URHucXd",
     "timestamp": 1527021178291
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#Data Quality Report \n",
    "#Coastal Pioneer, Offshore Profiler Mooring (CTD)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "**Evaluator: Amin Ilia**  \n",
    "amin.ilia@gmail.com \n",
    "\n",
    "**Evaluation Date**: 5/25/2018\n",
    "\n",
    "\n",
    "## 1. *Selected* instruments\n",
    "In this report, I will evaluate the CTD (specifically temperature and salinity) from the Pioneer Offshore Profiler Mooring (CP04OSPM), focusing on the 2015 year (Deployment 2, 3, and 4).\n",
    "\n",
    "###note: \n",
    "Due to stucking the wire durring two periods in 2015, I finally used  data for the peiod of 2015-10-13 to 2016-06-02, development 4 and 5 (see section 6)\n",
    "\n",
    "I will use shiboard CTD data, Pioneer-06 2015-05-12 to validate profiler data."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setup Instrument Variables\n",
    "site = 'CP04OSPM'        # CP04OSPM-WFP01-03-CTDPFK000\n",
    "node = 'WFP01'\n",
    "instrument = '03-CTDPFK000'\n",
    "method = 'recovered_wfp'\n",
    "stream = 'ctdpf_ckl_wfp_instrument_recovered'\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##2. Time periods of interest\n",
    "I will focus on the following time periods for evaluation:\n",
    "\n",
    "Jan 1, 2015 to Jan 01, 2016 - Deployment 2, 3, and 4 (see step 4)\n",
    "\n",
    "\n",
    "Oct 13, 2015 to June 02, 2016 (see step 6)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setup the Python processing environment \n",
    "import requests\n",
    "import datetime\n",
    "import pandas as pd\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "!pip install xarray\n",
    "!pip install dask\n",
    "import xarray as xr\n",
    "\n",
    "!pip install cmocean\n",
    "import cmocean\n",
    "\n",
    "!pip install netCDF4\n",
    "import netCDF4 as nc\n",
    "\n",
    "import re\n",
    "import os\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Related Metadata\n",
    "In this section, I will review some of metadata available in the system to make sure it is present and correct."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# API Information\n",
    "USERNAME ='OOIAPI-KLL1I93S2SW9WJ'\n",
    "TOKEN= 'TEMP-TOKEN-2FBVM6WBS4CHVN'\n",
    "DATA_API = 'https://ooinet.oceanobservatories.org/api/m2m/12576/sensor/inv'\n",
    "VOCAB_API = 'https://ooinet.oceanobservatories.org/api/m2m/12586/vocab/inv'\n",
    "ASSET_API = 'https://ooinet.oceanobservatories.org/api/m2m/12587'\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Specify some functions to convert timestamps\n",
    "ntp_epoch = datetime.datetime(1900, 1, 1)\n",
    "unix_epoch = datetime.datetime(1970, 1, 1)\n",
    "ntp_delta = (unix_epoch - ntp_epoch).total_seconds()\n",
    "\n",
    "def ntp_seconds_to_datetime(ntp_seconds):\n",
    "    return datetime.datetime.utcfromtimestamp(ntp_seconds - ntp_delta).replace(microsecond=0)\n",
    "  \n",
    "def convert_time(ms):\n",
    "  if ms != None:\n",
    "    return datetime.datetime.utcfromtimestamp(ms/1000)\n",
    "  else:\n",
    "    return None"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3a. Vocabulary Metadata\n",
    "Grab the basic vocabulary information (metadata) from the system to make sure we have the right instrument."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setup the API request url\n",
    "data_request_url ='/'.join((VOCAB_API,site,node,instrument))\n",
    "print(data_request_url)\n",
    "\n",
    "# Grab the information from the server\n",
    "r = requests.get(data_request_url, auth=(USERNAME, TOKEN))\n",
    "data = r.json()\n",
    "data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3b. Deployment Information\n",
    "Grab some information about the deployments for this instrument. I will grab all of the deployments available in the system for 2015 to 2017. Then I output the date ranges, latitude/longitude, asset ID, and sensor ID for each.  Note that the **reference designator** specified above represents the geographical location of an instrument across all deployments (e.g. the CTD on the Pioneer Upstream Offshore Profiler), the **Sensor ID** (and its Asset ID equivalent) represent the specific instrument used for a given deployment (i.e. a unique make, model, and serial numbered instrument)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setup the API request url\n",
    "data_request_url = ASSET_API + '/events/deployment/query'\n",
    "params = {\n",
    "  'beginDT':'2015-01-01T00:00:00.000Z',\n",
    "  'endDT':'2017-01-01T00:00:00.000Z',\n",
    "  'refdes':site+'-'+node+'-'+instrument,   \n",
    "}\n",
    "\n",
    "# Grab the information from the server\n",
    "r = requests.get(data_request_url, params=params, auth=(USERNAME, TOKEN))\n",
    "data = r.json()\n",
    "\n",
    "df = pd.DataFrame() # Setup empty array\n",
    "for d in data:\n",
    "  df = df.append({\n",
    "      'deployment': d['deploymentNumber'],\n",
    "      'start': convert_time(d['eventStartTime']),\n",
    "      'stop': convert_time(d['eventStopTime']),\n",
    "      'latitude': d['location']['latitude'],\n",
    "      'longitude': d['location']['longitude'],\n",
    "      'sensor': d['sensor']['uid'],\n",
    "      'asset_id': d['sensor']['assetId'],\n",
    "    }, ignore_index=True)\n",
    "df"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3c. Calibration Information\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setup the API request url\n",
    "data_request_url = ASSET_API + '/asset/cal'\n",
    "params = {\n",
    "  'beginDT':'2015-01-01T00:00:00.000Z',\n",
    "  'endDT':'2016-01-01T00:00:00.000Z',\n",
    "  'refdes':site+'-'+node+'-'+'04-FLORTK000',\n",
    "}\n",
    "\n",
    "# Grab the information from the server\n",
    "r = requests.get(data_request_url, params=params, auth=(USERNAME, TOKEN))\n",
    "data = r.json()\n",
    "\n",
    "# Reformat the data into a pretty table\n",
    "df = pd.DataFrame() # Setup empty array\n",
    "for d in data:\n",
    "  for dd in d['sensor']['calibration']:\n",
    "    for ddd in dd['calData']:\n",
    "      df = df.append({\n",
    "        'value': ddd['value'],\n",
    "        'start': convert_time(ddd['eventStartTime']),\n",
    "        'stop': convert_time(ddd['eventStopTime']),\n",
    "        'name': ddd['eventName'],\n",
    "        'assetUid': ddd['assetUid'],\n",
    "        }, ignore_index=True)\n",
    "    \n",
    "df = df.sort_values(by=['start','name'])\n",
    "df\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3d. Annotations\n",
    "Finally, let's pull any relevant annotations for the CTD instrument since 2015 to 2018."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ANNO_API = 'https://ooinet.oceanobservatories.org/api/m2m/12580/anno/find'\n",
    "params = {\n",
    "  'beginDT':int(datetime.date(2015,1,1).strftime('%s'))*1000,\n",
    "  'endDT':int(datetime.date(2018,1,1).strftime('%s'))*1000,\n",
    "  'refdes':site+'-'+node+'-'+instrument,\n",
    "}\n",
    "\n",
    "r = requests.get(ANNO_API, params=params, auth=(USERNAME, TOKEN))\n",
    "data = r.json()\n",
    "\n",
    "df = pd.DataFrame() # Setup empty array\n",
    "for d in data:\n",
    "  df = df.append({\n",
    "    'annotation': d['annotation'],\n",
    "    'start': convert_time(d['beginDT']),\n",
    "    'stop': convert_time(d['endDT']),\n",
    "    'site': d['subsite'],\n",
    "    'node': d['node'],\n",
    "    'sensor': d['sensor'],\n",
    "    'id': d['id']\n",
    "  }, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', -1) # Show the full annotation text\n",
    "df"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The wire stuck at top of its range after 2016-06-02 so We would use 2015."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. The full dataset\n",
    "Now let's take a look at a large range of data.  We shall look at all of Deployment 2, 3, and 4.  First we need to add some additional libraries to our Python environment."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "beginDT = '2015-01-01T01:01:01.500Z' \n",
    "endDT = '2016-01-01T01:01:01.500Z'\n",
    "\n",
    "data_request_url ='/'.join((DATA_API,site,node,instrument,method,stream))\n",
    "params = {\n",
    "    'beginDT':beginDT,\n",
    "    'endDT':endDT,   \n",
    "}\n",
    "r = requests.get(data_request_url, params=params, auth=(USERNAME, TOKEN))\n",
    "data = r.json()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data['allURLs'][0]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "check_complete = data['allURLs'][1] + '/status.txt'\n",
    "for i in range(1800): \n",
    "    r = requests.get(check_complete)\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        print('request completed')\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(1)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get data urls\n",
    "\n",
    "url = data['allURLs'][0]\n",
    "tdata_url_url = 'https://opendap.oceanobservatories.org/thredds/dodsC'\n",
    "datasets = requests.get(url).text\n",
    "urls = re.findall(r'href=[\\'\"]?([^\\'\" >]+)', datasets)\n",
    "x = re.findall(r'(ooi/.*?.nc)', datasets)\n",
    "for i in x:\n",
    "    if i.endswith('.nc') == False:\n",
    "        x.remove(i)\n",
    "for i in x:\n",
    "    try:\n",
    "        float(i[-4])\n",
    "    except:\n",
    "        x.remove(i)\n",
    "datasets = [os.path.join(tds_url, i) for i in x]\n",
    "datasets"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# load all data into a single array\n",
    "ds = xr.open_mfdataset(datasets)\n",
    "ds = ds.swap_dims({'obs': 'time'})    # swap dimension to time\n",
    "ds = ds.chunk({'time': 100})\n",
    "ds = ds.sortby('time') # data from different deployments can overlap so we want to sort all data by time stamp.\n",
    "ds"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Checking the data "
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check pressure data\n",
    "ds['ctdpf_ckl_seawater_pressure'].plot();"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Pressure data is not good."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check temperature data\n",
    "ds['ctdpf_ckl_seawater_temperature'].plot();"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check salinity data\n",
    "ds['practical_salinity'].plot();"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###note: \n",
    "It seems that the profiler stuck at botom before 2015-04-28 and gradually stuck at botom after 2015-07-20 and completly stucks at botom between 2015-08-05 and  2015-10-12. There isn't any annotation for these periods and I would report these to be added in annotation. "
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Changing focusing time period\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###Now I'm looking at the data since 2015-10-13 to 2016-06-02\n",
    "Full deployment 4 and part of developement 5"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "beginDT = '2015-10-13T01:01:01.500Z' \n",
    "endDT = '2016-06-02T01:01:01.500Z'\n",
    "\n",
    "data_request_url ='/'.join((DATA_API,site,node,instrument,method,stream))\n",
    "params = {\n",
    "    'beginDT':beginDT,\n",
    "    'endDT':endDT,   \n",
    "}\n",
    "r = requests.get(data_request_url, params=params, auth=(USERNAME, TOKEN))\n",
    "data = r.json()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data['allURLs'][0]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "check_complete = data['allURLs'][1] + '/status.txt'\n",
    "for i in range(1800): \n",
    "    r = requests.get(check_complete)\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        print('request completed')\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(1)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get data urls\n",
    "\n",
    "url = data['allURLs'][0]\n",
    "tds_url = 'https://opendap.oceanobservatories.org/thredds/dodsC'\n",
    "datasets = requests.get(url).text\n",
    "urls = re.findall(r'href=[\\'\"]?([^\\'\" >]+)', datasets)\n",
    "x = re.findall(r'(ooi/.*?.nc)', datasets)\n",
    "for i in x:\n",
    "    if i.endswith('.nc') == False:\n",
    "        x.remove(i)\n",
    "for i in x:\n",
    "    try:\n",
    "        float(i[-4])\n",
    "    except:\n",
    "        x.remove(i)\n",
    "datasets = [os.path.join(tds_url, i) for i in x]\n",
    "datasets"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# to aviod request data from database repeatedly \n",
    "datasets = ['https://opendap.oceanobservatories.org/thredds/dodsC/ooi/amin.ilia@gmail.com/20180524T140054-CP04OSPM-WFP01-03-CTDPFK000-recovered_wfp-ctdpf_ckl_wfp_instrument_recovered/deployment0005_CP04OSPM-WFP01-03-CTDPFK000-recovered_wfp-ctdpf_ckl_wfp_instrument_recovered_20160520T000003-20160602T002939.994915.nc',\n",
    " 'https://opendap.oceanobservatories.org/thredds/dodsC/ooi/amin.ilia@gmail.com/20180524T140054-CP04OSPM-WFP01-03-CTDPFK000-recovered_wfp-ctdpf_ckl_wfp_instrument_recovered/deployment0004_CP04OSPM-WFP01-03-CTDPFK000-recovered_wfp-ctdpf_ckl_wfp_instrument_recovered_20151013T030002-20160519T093808.996051.nc'];\n",
    "\n",
    "# load all data into a single array\n",
    "ds = xr.open_mfdataset(datasets)\n",
    "ds = ds.swap_dims({'obs': 'time'})    # swap dimension to time\n",
    "ds = ds.chunk({'time': 100})\n",
    "ds = ds.sortby('time') # data from different deployments can overlap so we want to sort all data by time stamp.\n",
    "ds"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check pressure data\n",
    "ds['ctdpf_ckl_seawater_pressure'].plot();"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check temperature data\n",
    "ds['ctdpf_ckl_seawater_temperature'].plot();"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check salinity data\n",
    "ds['practical_salinity'].plot();"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(16,6))\n",
    "ds['ctdpf_ckl_seawater_temperature'].plot.hist(bins=100, ax=ax1)\n",
    "ds['practical_salinity'].plot.hist(bins=100, ax=ax2);"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dtime = ds['time'].values\n",
    "pressure = ds['ctdpf_ckl_seawater_pressure'].values\n",
    "temperature = ds['ctdpf_ckl_seawater_temperature'].values\n",
    "salinity = ds['practical_salinity'].values"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, (ax1,ax2) = plt.subplots(2,1, sharex=True, sharey=True, figsize=(16,8))\n",
    "sc1 = ax1.scatter(dtime, pressure, c=temperature, cmap='RdYlBu_r', s=2)\n",
    "sc2 = ax2.scatter(dtime, pressure, c=salinity, cmap='GnBu', s=2)\n",
    "\n",
    "# Because the X and Y axes are shared, we only have to set limits once\n",
    "ax1.invert_yaxis() # Invert y axis\n",
    "ax1.set_xlim(dtime[0],dtime[-1]) # Set the time limits to match the dataset\n",
    "\n",
    "cbar = fig.colorbar(sc1, ax=ax1, orientation='vertical', extend='both')\n",
    "cbar.ax.set_ylabel('Temperature ($^\\circ$C)')\n",
    "cbar = fig.colorbar(sc2, ax=ax2, orientation='vertical', extend='both')\n",
    "cbar.ax.set_ylabel('Salinity')\n",
    "\n",
    "ax1.set_ylabel('Pressure (db)')\n",
    "ax2.set_ylabel('Pressure (db)')\n",
    "\n",
    "fig.suptitle(' Deployment 4 & 5')\n",
    "fig.subplots_adjust(top=0.95);\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "At October, there are high temprature gradiant in water profile. The water surface cooled and the mixed layer deepen after January. Temperature data seem to be reasonable. Track of fresh water from MAB can be seen at the surface from Salinity profile.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. Checking with satellite data\n",
    "\n",
    "* Surface temperature agreas with SST sattelite in October, although profiler just collect 10m depth data\n",
    "![SST for Oct 22, 2015](https://marine.rutgers.edu/cool/regions/bigbight/sst_comp/noaa/2015/img/151022.295.comp.lnt.jpg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Surface temperature agreas with SST sattelite in May, although profiler just collect 7m depth data\n",
    "\n",
    "\n",
    "\n",
    "![alt text](https://marine.rutgers.edu/cool/regions/bigbight/sst_comp/noaa/2016/img/160509.130.comp.lnt.jpg)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 8. Plotting monthly profiles\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds1 = ds.loc[dict(time=slice('2015-10-01','2015-11-01'))]\n",
    "a=ds1['practical_salinity'].values\n",
    "b=ds1['ctdpf_ckl_seawater_temperature'].values\n",
    "cc=ds1['ctdpf_ckl_seawater_pressure'].values"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sc = plt.scatter(a, b, c = cc, cmap=cmocean.cm.deep)\n",
    "plt.colorbar(sc)    \n",
    "plt.xlabel('Salinity')\n",
    "plt.ylabel('Temperature (C)')\n",
    "plt.title('Data for October 2015 from %s' % site);"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds1 = ds.loc[dict(time=slice('2015-11-01','2015-12-01'))]\n",
    "a=ds1['practical_salinity'].values\n",
    "b=ds1['ctdpf_ckl_seawater_temperature'].values\n",
    "cc=ds1['ctdpf_ckl_seawater_pressure'].values"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sc = plt.scatter(a, b, c = cc, cmap=cmocean.cm.deep)\n",
    "plt.colorbar(sc)    \n",
    "plt.xlabel('Salinity')\n",
    "plt.ylabel('Temperature (C)')\n",
    "plt.title('Data for November 2015 from %s' % site);"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "On November, it seems there was a problem for one of the diving of profiler. While the temperature data seems to be reasonable salinity data are not reasonable. "
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds1 = ds.loc[dict(time=slice('2015-12-01','2016-01-01'))]\n",
    "a=ds1['practical_salinity'].values\n",
    "b=ds1['ctdpf_ckl_seawater_temperature'].values\n",
    "cc=ds1['ctdpf_ckl_seawater_pressure'].values"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sc = plt.scatter(a, b, c = cc, cmap=cmocean.cm.deep)\n",
    "plt.colorbar(sc)    \n",
    "plt.xlabel('Salinity')\n",
    "plt.ylabel('Temperature (C)')\n",
    "plt.title('Data for December 2015 from %s' % site);"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds2 = ds.loc[dict(time=slice('2016-02-01','2016-03-01'))]\n",
    "a=ds2['practical_salinity'].values\n",
    "b=ds2['ctdpf_ckl_seawater_temperature'].values\n",
    "cc=ds2['ctdpf_ckl_seawater_pressure'].values"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sc = plt.scatter(a, b, c = cc, cmap=cmocean.cm.deep)\n",
    "plt.colorbar(sc)    \n",
    "plt.xlabel('Salinity')\n",
    "plt.ylabel('Temperature (C)')\n",
    "plt.title('Data for Feb 2016 from %s' % site);"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds3 = ds.loc[dict(time=slice('2016-05-01','2016-06-01'))]\n",
    "a=ds3['practical_salinity'].values\n",
    "b=ds3['ctdpf_ckl_seawater_temperature'].values\n",
    "cc=ds3['ctdpf_ckl_seawater_pressure'].values"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sc = plt.scatter(a, b, c = cc, cmap=cmocean.cm.deep)\n",
    "plt.colorbar(sc)    \n",
    "plt.xlabel('Salinity')\n",
    "plt.ylabel('Temperature (C)')\n",
    "plt.title('Data for May 2016 from %s' % site);"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot total data profiles\n",
    "sc = plt.scatter(salinity, temperature, \n",
    "            c = pressure, cmap=cmocean.cm.deep)\n",
    "plt.colorbar(sc)    \n",
    "plt.xlabel('Salinity')\n",
    "plt.ylabel('Temperature (C)')\n",
    "plt.title('Data from %s' % site);"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 9. Checking problem in Salinity in November 2015\n",
    "Plot data for the period of Nomber 10 to 15 to see what happen to salinity"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds1=ds.loc[dict(time=slice('2015-11-10','2015-11-15'))]\n",
    "dtime1 = ds1['time'].values\n",
    "salinity1 = ds1['practical_salinity'].values\n",
    "temperature1 = ds1['ctdpf_ckl_seawater_temperature'].values\n",
    "pressure1 = ds1['ctdpf_ckl_seawater_pressure'].values"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, (ax1,ax2) = plt.subplots(2,1, sharex=True, sharey=True, figsize=(16,8))\n",
    "sc1 = ax1.scatter(dtime1, pressure1, c=temperature1, cmap='RdYlBu_r', s=2)\n",
    "sc2 = ax2.scatter(dtime1, pressure1, c=salinity1, cmap='GnBu', s=2)\n",
    "\n",
    "# Because the X and Y axes are shared, we only have to set limits once\n",
    "ax1.invert_yaxis() # Invert y axis\n",
    "ax1.set_xlim(dtime1[0],dtime1[-1]) # Set the time limits to match the dataset\n",
    "# ax1.set_xlim([datetime.date(2015,11,1), datetime.date(2015,11,20)]) # Set the time limits to match the dataset\n",
    "\n",
    "cbar = fig.colorbar(sc1, ax=ax1, orientation='vertical', extend='both')\n",
    "cbar.ax.set_ylabel('Temperature ($^\\circ$C)')\n",
    "cbar = fig.colorbar(sc2, ax=ax2, orientation='vertical', extend='both')\n",
    "cbar.ax.set_ylabel('Salinity')\n",
    "\n",
    "ax1.set_ylabel('Pressure (db)')\n",
    "ax2.set_ylabel('Pressure (db)')\n",
    "\n",
    "fig.suptitle('CP04OSPM Deployment 4 & 5')\n",
    "fig.subplots_adjust(top=0.95);"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 10. Comparing with Cruise CTD data\n",
    "For cruise data, I used the data collected during the Pioneer 6 Cruise, Leg 1, Cast #02, which occurred on 2016-05-12 UTC."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Down and Up Casts\n",
    "cruise_data_file = 'https://alfresco.oceanobservatories.org/alfresco/d/d/workspace/SpacesStore/f774f6ed-4a34-4943-8445-f3884c67d234/ar04a002.asc'\n",
    "\n",
    "# Read in the data file without headers due to a bug in the file (two of the header names run together)\n",
    "cruise_data = pd.read_table(cruise_data_file, delim_whitespace=True, header=None, skiprows=1)\n",
    "\n",
    "# Add back the necessary headers\n",
    "cruise_data = cruise_data.rename(columns={0:'Pressure', 1:'Temperature', 10:'Salinity'})\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cruise_data.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Next let's grab the Profiler data using a synchronous request \n",
    "data_request_url ='/'.join((DATA_API,site,node,instrument,method,stream))\n",
    "\n",
    "params = {\n",
    "  'beginDT':'2016-05-12T00:00:00.000Z',\n",
    "  'endDT':'2016-05-13T00:00:00.000Z',\n",
    "  'limit':1000,\n",
    "}\n",
    "\n",
    "# Grab the data\n",
    "r = requests.get(data_request_url, params=params, auth=(USERNAME, TOKEN))\n",
    "data = r.json()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Process the returned JSON dataset into something we can work with\n",
    "p_time = []\n",
    "p_temp = []\n",
    "p_sal = []\n",
    "p_pr = []\n",
    "for i in range(len(data)):\n",
    "  p_time.append(ntp_seconds_to_datetime(data[i]['time']))\n",
    "  p_temp.append(data[i]['ctdpf_ckl_seawater_temperature'])\n",
    "  p_sal.append(data[i]['practical_salinity'])\n",
    "  p_pr.append(data[i]['ctdpf_ckl_seawater_pressure'])\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Now let's plot the Cruise and Profiler data together\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "ax1.plot(cruise_data.Temperature,cruise_data.Pressure,'b')\n",
    "ax1.plot(p_temp,p_pr,'r.')\n",
    "ax1.set_xlabel('Temperature (C)')\n",
    "ax1.set_ylabel('Pressure (dm)')\n",
    "# ax1.invert_yaxis()\n",
    "ax1.set_ylim(475,0)\n",
    "\n",
    "ax2.plot(cruise_data.Salinity,cruise_data.Pressure,'b',label='Cruise CTD')\n",
    "ax2.plot(p_sal,p_pr,'r.',label='Pioneer Profiler')\n",
    "ax2.set_xlabel('Salinity (psu)')\n",
    "\n",
    "fig.suptitle('CP04OSPM Compared with Shipboard CTD on 05/12/2016')\n",
    "fig.subplots_adjust(top=0.9)\n",
    "\n",
    "legend = ax2.legend(loc='lower right', shadow=True, fontsize='small');\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In general, the data from the CTD cast aligns nicely with the profiler data from the same day.  Interestingly, the up and down casts from the shipboard CTD match very well, which often isn't the case.  The profiler matches in general terms with the ship, but there is a bit of variability around the profile Specially near the surface water. "
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 11. Conclusion\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Based on this analysis of the Coastal Pioneer, Offshore Profiler Mooring, I note the following takeaways:\n",
    "* The profiler was inoperative during the end of Deployments 2, 3, and 5; however the CTD data still appears reasonable. \n",
    "* For Deployment 2 the profiler stuck at top (depth 55m) before 2015-04-28. For Deployment 3, after 2015-07-20, the profiler gradually stuck at bottom and then between 2015-08-05 and 2015-10-12 completely stuck at bottom (depth 420m). There isn't any annotation about it in the system therefore the annotation concerning these should be added in the system. \n",
    "\n",
    "* Temperature and salinity variability for the period of October 13, 2015 to June 02, 2016 were plotted.\n",
    "* In general, the temperature, salinity and pressure values during deployment 4 and the beginning of deployment 5 (until 2016-06-02) look largely reasonable. There are no major outliers.\n",
    "* The data seems to align with known physical processes, there is shallow mixed layer in the fall, but the mixed layer is deepened during winter and temperature profile is became uniform\n",
    "* The cruise CTD data for the May 12, 2016 were compared with profiler data. The data generally have good agreement.\n",
    "\n",
    "* On November 11 in 2015, the profiler observed some high and unusual salinity while diving. However temperature data are quite reseanable. It can be due to a small problem in conductivity sensor. \n",
    "\n",
    "* Accessing OOI data using Python can be fun and I really enjoyed the OOI Physics workshop.\n"
   ]
  }
 ]
}
