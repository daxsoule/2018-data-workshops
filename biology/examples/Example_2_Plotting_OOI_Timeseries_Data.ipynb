{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Example 2 - Plotting OOI Timeseries Data.ipynb",
   "version": "0.3.2",
   "views": {},
   "default_view": {},
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ooi",
   "language": "python",
   "name": "ooi"
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Example 2 - Plotting OOI Time Series Data (from NetCDF files)\n",
    "*Written by Sage Lichtenwalner, Rutgers University, June 7, 2018, with help from Friedrich Knuth*\n",
    "\n",
    "In this example we show how to programmatically download and work with NetCDF time series data from the OOI.  \n",
    "\n",
    "We will use the data files created using Example 1, so please refer to that example first to find out how to request a specific dataset.\n",
    "\n",
    "For reference, we will be using the [30m CTD on Global Papa Flanking Mooring B](http://ooi.visualocean.net/instruments/view/GP03FLMB-RIM01-02-CTDMOG060)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Loading xarray\n",
    "Before we get started, we first need to install and load the xarray library into Google Colab."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!pip install dask\n",
    "!pip install netcdf4\n",
    "!pip install xarray\n",
    "import xarray as xr"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## The dataset \n",
    "In the previous example, we made an **Asynchronous** data request using the OOI API. We then received a two different URLs where the resulting data files can be found, a THREDDS version and a regular web site link.\n",
    "\n",
    "Whenever you make a download request, whether you use the data portal or the API, you should also receive an email with the links in case you forgot to save them when you made the request.\n",
    "\n",
    "In Example 1, the first URL was to the THREDDS catalog version of our dataset, which is what we'll need.  For reference, here is the [link](https://opendap.oceanobservatories.org/thredds/catalog/ooi/ooidatateam@gmail.com/20180614T193502-GP03FLMB-RIM01-02-CTDMOG060-telemetered-ctdmo_ghqr_sio_mule_instrument/catalog.html)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Loading a single NetCDF data file"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In Example 1, we requested 2 years of data (from 7/1/2015 to 7/1/2016).  This resulted in a number of files in the output directory, but only 2 key NetCDF (.nc) data files.  \n",
    "\n",
    "*By default, the system will break up data files into individual deployments.  It will also break up the deployments if the files are larger than ~500MB.*\n",
    "\n",
    "If we only want to load a **single NetCDF data file** (perhaps we only want one deployment or we only have one file), we could easily load it by specifying the direct link to the `.nc` file.  \n",
    "\n",
    "To choose a single deployment file from the THREDDS catalog...\n",
    "* click on the deployment/file you wish to use \n",
    "* then click on the \"OPENDAP\" link\n",
    "* and then copy the \"Data URL\" from the text box.\n",
    "\n",
    "We'll add that link here as a variable."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "single_file = 'https://opendap.oceanobservatories.org/thredds/dodsC/ooi/ooidatateam@gmail.com/20180615T033324-GP03FLMB-RIM01-02-CTDMOG060-recovered_inst-ctdmo_ghqr_instrument_recovered/deployment0003_GP03FLMB-RIM01-02-CTDMOG060-recovered_inst-ctdmo_ghqr_instrument_recovered_20150701T000001-20160703T183001.nc'"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can now easily load this file using xarray."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the data files\n",
    "ds = xr.open_dataset(single_file)\n",
    "\n",
    "# By default, OOI datasets use the 'obs' variable as the index, but time is more convenient\n",
    "ds = ds.swap_dims({'obs': 'time'})\n",
    "\n",
    "ds "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Plotting Timeseries Data\n",
    "And now we can easily use the built in matplotlib plotting routines in xarray to make a plot."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds['ctdmo_seawater_temperature'].plot();"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can also quickly make a histogram."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds['ctdmo_seawater_temperature'].plot.hist(bins=100);"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As we can plot a bunch of variables at once."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(3,1, sharex=True, figsize=(12,7))\n",
    "ds['ctdmo_seawater_temperature'].plot(ax=ax1)\n",
    "ds['practical_salinity'].plot(ax=ax2)\n",
    "ds['ctdmo_seawater_pressure'].plot(ax=ax3);\n",
    "ax2.set_ylim(30,35);"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Loading and concatenating multiple files"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can also concatenate multiple .nc files using xarray.  First we need to build up a list of all of the files we wish to include.  To start, let's specify the THREDDS url which contains all of our data files."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "url = 'https://opendap.oceanobservatories.org/thredds/catalog/ooi/ooidatateam@gmail.com/20180615T033324-GP03FLMB-RIM01-02-CTDMOG060-recovered_inst-ctdmo_ghqr_instrument_recovered/catalog.html'\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Next, we can use the following code to automatically find all of the available .nc files in the directory.  "
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tds_url = 'https://opendap.oceanobservatories.org/thredds/dodsC'\n",
    "datasets = requests.get(url).text\n",
    "urls = re.findall(r'href=[\\'\"]?([^\\'\" >]+)', datasets)\n",
    "x = re.findall(r'(ooi/.*?.nc)', datasets)\n",
    "for i in x:\n",
    "    if i.endswith('.nc') == False:\n",
    "        x.remove(i)\n",
    "for i in x:\n",
    "    try:\n",
    "        float(i[-4])\n",
    "    except:\n",
    "        x.remove(i)\n",
    "datasets = [os.path.join(tds_url, i) for i in x]\n",
    "datasets"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "(Note, when requesting data from some instruments, you will actually get data files from multiple instruments, when they are needed to calculate derived parameters.  If this happens, you will need to modify the code above or tweak the resultant list to make sure you only include .nc files from the instrument you are interested in.)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now we can use `open_mfdataset()` to load all files into a single xarray dataset."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds = xr.open_mfdataset(datasets)\n",
    "ds = ds.swap_dims({'obs': 'time'}) # Swap the primary dimension\n",
    "ds = ds.chunk({'time': 100}) # Used for optimization\n",
    "ds = ds.sortby('time') # Data from different deployments can overlap so we want to sort all data by time stamp.\n",
    "ds"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "And now a plot of this larger dataset."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds['ctdmo_seawater_temperature'].plot();"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "And now all the plots again."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(3,1, sharex=True, figsize=(12,7))\n",
    "ds['ctdmo_seawater_temperature'].plot(ax=ax1)\n",
    "ds['practical_salinity'].plot(ax=ax2)\n",
    "ds['ctdmo_seawater_pressure'].plot(ax=ax3);\n",
    "ax2.set_ylim(30,35);"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let's try it again using dots instead of lines."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(3,1, sharex=True, figsize=(12,7))\n",
    "ds['ctdmo_seawater_temperature'].plot(ax=ax1,linestyle='None',marker='.',markersize=1)\n",
    "ds['practical_salinity'].plot(ax=ax2,linestyle='None',marker='.',markersize=1)\n",
    "ds['ctdmo_seawater_pressure'].plot(ax=ax3,linestyle='None',marker='.',markersize=1);\n",
    "ax2.set_ylim(30,35);"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Identifying the Sampling Frequency\n",
    "We can use the following snippet of code to find out the typical sampling frequency of the dataset.  Note, this may take a while to calculate."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df = ds.to_dataframe()\n",
    "res = (pd.Series(df.index[1:]) - pd.Series(df.index[:-1])).value_counts()\n",
    "res"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Investigating Metadata (variable and attribute selection)\n",
    "Thanks to xarray, we can easily access the global metadata as well as the metadata for individual variables.  You can refer to the full list of variables an attributes outputted above.\n",
    "\n",
    "Here are a few examples."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds.source"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'%s-%s-%s' % (ds.subsite,ds.node,ds.sensor)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds['ctdmo_seawater_pressure']"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import textwrap\n",
    "textwrap.wrap(ds['ctdmo_seawater_pressure'].comment)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds['ctdmo_seawater_pressure'].dims"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds['ctdmo_seawater_pressure'].coords"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds['ctdmo_seawater_pressure'].coords['pressure'].units"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Some quick statistics\n",
    "We can convert the **xarray Dataset** into a **padas Dataframe** to do some quick statistical calculations.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = ds[['ctdmo_seawater_temperature','practical_salinity','ctdmo_seawater_pressure']].to_dataframe()\n",
    "df = df.drop(columns=['pressure','obs']) #Drop unnecessary columns\n",
    "df.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prepare to be blown away...\n",
    "df.describe()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Downsampling\n",
    "We can also easily calculate hourly, daily and monthly averages.  See the pandas [`resample()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.resample.html) doc for more, as well as this list of [offset options](http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases).\n",
    "\n",
    "That said, if you want to use centered averaging, moving averages, or other more complicated averaging or filtering routines using irregular intervals, you might have to roll-your-own code."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16, 6)\n",
    "df['ctdmo_seawater_temperature'].plot(ax=ax,label='Raw',linestyle='None',marker='.',markersize=2)\n",
    "df['ctdmo_seawater_temperature'].resample('D').mean().plot(ax=ax,label='Daily')\n",
    "df['ctdmo_seawater_temperature'].resample('MS').mean().plot(ax=ax,label='Monthly',marker='d')\n",
    "plt.legend();"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creating and downloading a CSV file\n",
    "Above we converted our xarray Dataset into a pandas Dataframe.  Xarray is great for loading and exporting netcdf data, while Pandas is great for doing the same with CSV.\n",
    "\n",
    "Now that we have our data in a pandas Data frame, we can easily use the `.to_csv()` method to create a CSV file."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.to_csv('output.csv') # Create the CSV file\n",
    "# ! gzip output.csv"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ls -l"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "If you're using Google Colab, these file live in the cloud, so you need to use some fancy code to save the file to your Google Drive so you can access it.  (See this [example notebook](https://colab.research.google.com/notebooks/io.ipynb) for more.)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from google.colab import files\n",
    "# files.download('output.csv') # Download from Google Colab\n",
    "\n",
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once in a notebook.\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once in a notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create & upload a file.\n",
    "uploaded = drive.CreateFile({'title': 'test_output.csv'}) # File to be create on Drive\n",
    "uploaded.SetContentFile('output.csv') # Local file to copy\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Bokeh Plots\n",
    "Finally, let's create an interactive plot using the Bokeh library."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import Bokeh functions\n",
    "!pip install bokeh\n",
    "import os\n",
    "from bokeh.plotting import figure, output_file, reset_output, show, ColumnDataSource, save\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models import BoxAnnotation\n",
    "from bokeh.io import output_notebook"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's downsample temperature a big\n",
    "ds2 = ds['ctdmo_seawater_temperature'][0::10] #Start/Stop/Stride\n",
    "ds2"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "source = ColumnDataSource(\n",
    "    data=dict(\n",
    "        x=list(ds2.time.values),\n",
    "        y=list((ds2.values*-1))\n",
    "    )\n",
    ")\n",
    "\n",
    "s = figure(width=800,\n",
    "           height=400,\n",
    "           title='Global Papa Flanking Subsurface Mooring B Mooring Riser CTD (30 m)',\n",
    "           x_axis_label='Time (GMT)',\n",
    "           y_axis_label='Temperature (C)',\n",
    "           x_axis_type='datetime')\n",
    "\n",
    "# s.line('x', 'y', line_width=3, source=source)\n",
    "s.circle('x', 'y', fill_color='white', size=4, source=source)\n",
    "\n",
    "output_notebook()\n",
    "show(column(s))\n",
    "\n",
    "# output_file(os.getcwd())\n",
    "# save(s, filename='pressure.html')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "So that's the quick tour of some of the things you can do in Python with OOI timeseries datasets.  In Example 3, we will show you some additional tricks to use when working with vertical profiler or glider data."
   ]
  }
 ]
}
