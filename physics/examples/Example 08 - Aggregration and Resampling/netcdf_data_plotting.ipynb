{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with OOI NetCDF Data\n",
    "\n",
    "In this example we show how to work with the data downloaded via the netcdf_data_requests notebook. Go there first to understand how data is requested from the system and downloaded to a thredds server for retrieval, before proceeding with this notebook.\n",
    "\n",
    "We will use data from the 3D Thermistory Array deployed in the ASHES Vent field at Axial Seamount for this example, but the mechanics apply to all datasets that are processed through the OOI Cyberinfrastructure (CI) system. You wil learn:\n",
    "\n",
    "* how to load the NetCDF data into your notebook, once the data request has completed (see notebook netcdf_data_requests)\n",
    "* how to explore and plot data\n",
    "\n",
    "\n",
    "A great resource for data wrangling and exploration in python can be found at https://chrisalbon.com/. Tip: add \"albon\" to your search in google when trying to find a common technique and chances are Chris Albon has made a post on how to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we are using data from the 3D Thermistor Array (TMPSF)\n",
    "http://ooi.visualocean.net/instruments/view/RS03ASHS-MJ03B-07-TMPSFA301\n",
    "\n",
    "![RS03ASHS-MJ03B-07-TMPSFA301](https://github.com/ooi-data-review/ooi_datateam_notebooks/raw/master/images/RS03ASHS-MJ03B-07-TMPSFA301.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paste the thredds url you received by downloading the data from the netcdf_data_requests notebook, or use the one provided below.  \n",
    "\n",
    "We will parse the html at the location where the files are being delivered to get the list of the NetCDF files written to THREDDS. Note that seperate NetCDF files are created at 500 mb intervals and when there is a new deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://opendap.oceanobservatories.org/thredds/catalog/ooi/ooidatateam@gmail.com/20180517T182049-RS03ASHS-MJ03B-07-TMPSFA301-streamed-tmpsf_sample/catalog.html'\n",
    "tds_url = 'https://opendap.oceanobservatories.org/thredds/dodsC'\n",
    "datasets = requests.get(url).text\n",
    "urls = re.findall(r'href=[\\'\"]?([^\\'\" >]+)', datasets)\n",
    "x = re.findall(r'(ooi/.*?.nc)', datasets)\n",
    "for i in x:\n",
    "    if i.endswith('.nc') == False:\n",
    "        x.remove(i)\n",
    "for i in x:\n",
    "    try:\n",
    "        float(i[-4])\n",
    "    except:\n",
    "        x.remove(i)\n",
    "datasets = [os.path.join(tds_url, i) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use xarray to open all netcdf files as a single xarray datase, swap the dimention from obs to time and and examine the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_mfdataset(datasets)\n",
    "ds = ds.swap_dims({'obs': 'time'})\n",
    "ds = ds.chunk({'time': 100})\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use built in xarray plotting functions to create simple line plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['temperature12'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tell that the peak temperature is increatsing, but this simple line plot does not reveal the internal data distribution. Let's convert to pandas dataframe and downsample from 1 Hz to 1/60 Hz. This step may take 5-10 minutes. More ram will be allocated during the workshop to expedite processing. If the step fails entirely for any reason, please send us a note on slack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from dask.diagnostics import ProgressBar\n",
    "with ProgressBar():\n",
    "    df = ds['temperature12'].to_dataframe()\n",
    "    df = df.resample('min').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plt.close()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16, 6)\n",
    "df['temperature12'].plot(ax=ax)\n",
    "df['temperature12'].resample('H').mean().plot(ax=ax)\n",
    "df['temperature12'].resample('D').mean().plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are getting a better sense of the data. Let's convert time to ordinal, grab temperature values and re-examine using hexagonal bi-variate binning. Again, this step may take a few minutes, but should run faster during the workshop. If the step fails entirely for any reason, please send us a note on slack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "time = []\n",
    "time_pd = pd.to_datetime(ds.time.values.tolist())\n",
    "for i in time_pd:\n",
    "    i = np.datetime64(i).astype(datetime.datetime)\n",
    "    time.append(dates.date2num(i)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = ds['temperature12'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16, 6)\n",
    "\n",
    "hb1 = ax.hexbin(time, temperature, bins='log', vmin=0.4, vmax=3, gridsize=(1100, 100), mincnt=1, cmap='Blues')\n",
    "fig.colorbar(hb1)\n",
    "ax.yaxis.grid(True)\n",
    "ax.xaxis.grid(True)\n",
    "# ax.set_xlim(datetime.datetime(2015, 12, 1, 0, 0),datetime.datetime(2016, 7, 25, 0, 0))\n",
    "# ax.set_ylim(2,11)\n",
    "years = dates.YearLocator()\n",
    "months = dates.MonthLocator()\n",
    "yearsFmt = dates.DateFormatter('\\n\\n\\n%Y')\n",
    "monthsFmt = dates.DateFormatter('%b')\n",
    "ax.xaxis.set_major_locator(months)\n",
    "ax.xaxis.set_major_formatter(monthsFmt)\n",
    "ax.xaxis.set_minor_locator(years)\n",
    "ax.xaxis.set_minor_formatter(yearsFmt)\n",
    "plt.tight_layout()\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=90)\n",
    "plt.ylabel('Temperature $^\\circ$C')\n",
    "plt.xlabel('Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OOI",
   "language": "python",
   "name": "ooi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
