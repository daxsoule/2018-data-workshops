{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling cabled FLORT data\n",
    "*Written by Friedrich Knuth, Rutgers University*\n",
    "\n",
    "*Revised by Lori Garzio, Rutgers University, July 12, 2018*\n",
    "\n",
    "This example demonstrates how to download data via the OOI API, downsample the data (in this case, because cabled data are collected at a high frequency), and save the more manageable downsampled data as a pickle file. Once you have your pickle file with the data you want, you can use the 02_plot_pk.ipynb script to visualize the data.\n",
    "\n",
    "The downsampled pickle file from this example is created and saved in this directory for reference (chlor_a_and_temp.pd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your API username and password\n",
    "username = ''\n",
    "token = ''\n",
    "\n",
    "# Specify data for request\n",
    "subsite = 'RS01SBPS'\n",
    "node = 'SF01A'\n",
    "sensor = '3A-FLORTD101'\n",
    "method = 'streamed'\n",
    "stream = 'flort_d_data_record'\n",
    "beginDT = '2014-09-01T01:01:01.000Z'\n",
    "endDT = '2018-06-30T01:01:01.000Z'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and send the request. \n",
    "#### Note: Data request lines are commented out to prevent accidental resubmission when running through the entire notebook quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://ooinet.oceanobservatories.org/api/m2m/12576/sensor/inv/'\n",
    "\n",
    "data_request_url ='/'.join((base_url,subsite,node,sensor,method,stream))\n",
    "params = {\n",
    "    'beginDT':beginDT,\n",
    "    'endDT':endDT,   \n",
    "}\n",
    "\n",
    "# r = requests.get(data_request_url, params=params, auth=(username, token))\n",
    "# data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THREDDs directory containing data files\n",
    "# data['allURLs'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for the data request to complete. Note: this may take a while if you have requested a large time range of cabled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "check_complete  = data['allURLs'][1] + '/status.txt'\n",
    "for i in range(1800): \n",
    "    r = requests.get(check_complete)\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        print('request completed')\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all of the .nc files in the THREDDs directory\n",
    "url = data['allURLs'][0] # or copy and paste the THREDDs url here\n",
    "# url = 'https://opendap.oceanobservatories.org/thredds/catalog/ooi/ooidatateam@gmail.com/20180712T150853-RS01SBPS-SF01A-3A-FLORTD101-streamed-flort_d_data_record/catalog.html'\n",
    "tds_url = 'https://opendap.oceanobservatories.org/thredds/dodsC'\n",
    "datasets = requests.get(url).text\n",
    "urls = re.findall(r'href=[\\'\"]?([^\\'\" >]+)', datasets)\n",
    "x = re.findall(r'(ooi/.*?.nc)', datasets)\n",
    "for i in x:\n",
    "    if i.endswith('.nc') == False:\n",
    "        x.remove(i)\n",
    "for i in x:\n",
    "    try:\n",
    "        float(i[-4])\n",
    "    except:\n",
    "        x.remove(i)\n",
    "datasets = [os.path.join(tds_url, i) for i in x]\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of only the FLORT files (exclude files from other instruments that might also be provided in the data request)\n",
    "datasets_sel = []\n",
    "for i in datasets:\n",
    "    if '2A-CTDPFA102' in i:\n",
    "        pass\n",
    "    else:\n",
    "        datasets_sel.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the output directory for the pickle files that are created below\n",
    "new_dir = 'minute_mean_data/'\n",
    "if not os.path.isdir(new_dir):\n",
    "    try:\n",
    "        os.makedirs(new_dir)\n",
    "    except OSError:\n",
    "        if os.path.exists(new_dir):\n",
    "            pass\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each .nc file: open the file, resample the chlorophyll a and temperature data by taking minute averages, and save the information to a pickle file. This step might take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for i in datasets_sel:\n",
    "    print('Downsampling file {} of {}'.format(str(num + 1), str(len(datasets_sel))))\n",
    "    ds = xr.open_dataset(i)\n",
    "    ds = ds.swap_dims({'obs': 'time'})\n",
    "\n",
    "    chlor_a_min = pd.DataFrame()\n",
    "    chlor_a_min['fluorometric_chlorophyll_a'] = ds['fluorometric_chlorophyll_a'].to_pandas().resample('T').mean()\n",
    "    chlor_a_min['int_ctd_pressure'] = ds['int_ctd_pressure'].to_pandas().resample('T').mean()\n",
    "\n",
    "    ds['seawater_temperature'].attrs.pop('units')\n",
    "    chlor_a_min['seawater_temperature'] = ds['seawater_temperature'].to_pandas().resample('T').mean()\n",
    "\n",
    "    chlor_a_min = chlor_a_min.dropna()\n",
    "\n",
    "    out = 'minute_mean_data/' + i.split('/')[-1][:-3] + '_resampled' + '.pd'\n",
    "    num = num +1\n",
    "\n",
    "    with open(out, 'wb') as fh:\n",
    "        pk.dump(chlor_a_min,fh)\n",
    "\n",
    "    gc.collect()\n",
    "print('Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine each individual pickle file to one file. An alternative would be to write the information to a single pickle file in the previous code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a single file with all the pickled data.\n",
    "chlor_a_and_temp = pd.DataFrame()\n",
    "for path, subdirs, files in os.walk('minute_mean_data/'):\n",
    "    for name in files:\n",
    "        file_name = os.path.join(path, name)\n",
    "        with open(file_name, 'rb') as f:\n",
    "            pd_df = pk.load(f)\n",
    "            chlor_a_and_temp = chlor_a_and_temp.append(pd_df)\n",
    "\n",
    "with open('chlor_a_and_temp.pd', 'wb') as f:\n",
    "    pk.dump(chlor_a_and_temp,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
